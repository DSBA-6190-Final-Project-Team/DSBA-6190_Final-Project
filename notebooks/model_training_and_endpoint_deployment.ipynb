{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is based on the preprocessing already locally performed. Training and Validation sets of images and LST files have been developed and placed in the correct structure, on S3. \n",
    "\n",
    "At this point, we can now simply perform the multiclass image classification training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time as t\n",
    "import os\n",
    "import json\n",
    "import sagemaker\n",
    "import boto3\n",
    "import pprint\n",
    "import posixpath\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish AWS Parameters\n",
    "This step establishes parameters used for AWS connections and other global inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_algorithm_name = 'image-classification'\n",
    "bucket = \"dsba-6190-final-team-project\"\n",
    "prefix_1 = \"channels\"\n",
    "prefix_file_type = \"rec\"\n",
    "region = \"us-east-1\"\n",
    "label = \"image-classification-drivers\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sessions and Clients\n",
    "With these inputs we'll establish the necessary sessions and clients to operate this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boto3 Session\n",
    "boto_sess = boto3.session.Session(region_name=region)\n",
    "\n",
    "# Sagemaker Session\n",
    "sess_sage = sagemaker.session.Session(boto_session=boto_sess)\n",
    "\n",
    "# IAM client\n",
    "iam_client = boto_sess.client('iam')\n",
    "\n",
    "# Sagemaker Client\n",
    "sm_client = boto_sess.client('sagemaker')\n",
    "\n",
    "# App Autoscale Client\n",
    "scale_client = boto_sess.client(\"application-autoscaling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Role Definition\n",
    "I will define the role for the actions in this notebook. If working outside the AWS environment, make sure the AWS credentials are properly located. Instead of hardcoding the role ARN into the notebook, we will use the boto3 tools to extract the role ARN based on a known role name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::726963482731:role/dsba_6190_team_project\n"
     ]
    }
   ],
   "source": [
    "# Create List of All Roles associated with AWS Credentials\n",
    "role_list = iam_client.list_roles()['Roles']\n",
    "\n",
    "# Define Key/Value for role name \n",
    "key, value = 'RoleName', 'dsba_6190_team_project'\n",
    "\n",
    "#Initialize Role ARN variable\n",
    "role_arn= ''\n",
    "\n",
    "for item in role_list:\n",
    "    if key in item and value == item[key]:\n",
    "        role_arn = item['Arn']\n",
    "\n",
    "# Verify Role ARN\n",
    "print(role_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also define the ARN for the Autoscaling Role we will use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::726963482731:role/aws-service-role/sagemaker.application-autoscaling.amazonaws.com/AWSServiceRoleForApplicationAutoScaling_SageMakerEndpoint\n"
     ]
    }
   ],
   "source": [
    "# Define Key/Value for role name \n",
    "key, value = 'RoleName', 'AWSServiceRoleForApplicationAutoScaling_SageMakerEndpoint'\n",
    "\n",
    "#Initialize Role ARN variable\n",
    "role_arn_auto_sc= ''\n",
    "\n",
    "for item in role_list:\n",
    "    if key in item and value == item[key]:\n",
    "        role_arn_auto_sc = item['Arn']\n",
    "\n",
    "# Verify Role ARN\n",
    "print(role_arn_auto_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Sagemaker Model\n",
    "This step imports the latest version of the Amazon Sagemaker Image Classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "811284229777.dkr.ecr.us-east-1.amazonaws.com/image-classification:latest\n"
     ]
    }
   ],
   "source": [
    "training_image = get_image_uri(region_name = sess_sage.boto_region_name, \n",
    "                               repo_name = sagemaker_algorithm_name, \n",
    "                               repo_version =\"latest\")\n",
    "print (training_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "Two different data sets have been uploaded to S3. One is the complete dataset. The other is a 10% sample of the dataset. The 10% sample is for troubleshooting training and deployment of the Sagemaker Image Classification algorithm.\n",
    "\n",
    "There are only two differences between training the model with the sample or complete dataset:\n",
    "\n",
    "* __Input Location__: We need to point the algorithm to different S3 locations. We will do this with the **prefix_dataset** variable, which will be defined at the beginning of each dataset's notebook section.\n",
    "* __Number of Training Samples__: The number of training samples will be different for the complete and the sample. Thes values are available in the Jupyter Notebook used to split the data and upload to S3.\n",
    "\n",
    "We will define the number of **training** samples for each dataset below. \n",
    "\n",
    "**Note**: *Currently this is a manual process. Future iterations of this process will automate this calculation.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_training_samples_complete = 15686\n",
    "num_training_samples_10 = 1567"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dataset\n",
    "This section defines the parameters of the dataset. By setting the split prefix and dataset prefix, it will direct the algorithm to the correct training and validation inputs. \n",
    "\n",
    "There are two varables which require definition:\n",
    "\n",
    "1. **Dataset**: The dataset is either the complete dataset, or it is the 10% sample dataset. The 10% sample was created for troubleshooting purposes. Final production will use the complete dataset.\n",
    "2. **Train/Validation Split Method**: Two different methods were developed to split the training data into a training and validation set. See the image processing notebook for more detail.\n",
    " * im2rec: This method was a random split, using the **im2rec.py** tool\n",
    " * split_drivers: This method divided the drivers into a training and validation set. Then, all the images associated with each driver are put into image training and validation sets. Using this method, all of the images associated with a driver are in either the training or validation set. No driver appears in both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are the inputs for the model:\n",
      "Split Method:\t\t\tsplit_random\n",
      "Dataset:\t\t\tsample\n",
      "# of Training Samples:\t\t1567\n"
     ]
    }
   ],
   "source": [
    "# Define Lists and Dictionary\n",
    "list_dataset = [\"complete\", \"sample\",]\n",
    "list_split_method = [\"split_random\", \"split_driver\"]\n",
    "\n",
    "training_sample_dict = {\n",
    "    \"sample-split_random\" : num_training_samples_10,\n",
    "    \"sample-split_driver\": num_training_samples_10, \n",
    "    \"complete-split_random\": num_training_samples_complete,\n",
    "    \"complete-split_driver\": num_training_samples_complete    \n",
    "}\n",
    "\n",
    "# Define Data Inputs\n",
    "prefix_dataset = list_dataset[0] #0 = complete / 1 = sample\n",
    "prefix_split_type = list_split_method[0]  #0 = split_random / 1 = split_drivers\n",
    "\n",
    "# Extract Number of Training Samples\n",
    "key_training_sample = prefix_dataset + \"-\" +prefix_split_type\n",
    "num_training_samples = training_sample_dict[key_training_sample]\n",
    "\n",
    "print(\"The following are the inputs for the model:\")\n",
    "print(\"Split Method:\\t\\t\\t{}\".format(prefix_split_type))\n",
    "print(\"Dataset:\\t\\t\\t{}\".format(prefix_dataset))\n",
    "print(\"# of Training Samples:\\t\\t{}\".format(num_training_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Output Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://dsba-6190-final-team-project/output\n"
     ]
    }
   ],
   "source": [
    "s3_output_location = 's3://{}/output'.format(bucket)\n",
    "print(s3_output_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Input Location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we establish the data input channels. As we are using RecordIO data format, only two channels are required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input data is pulled from the following S3 locations:\n",
      "Training:\ts3://dsba-6190-final-team-project/channels/split_random/sample/train/\n",
      "Validation:\ts3://dsba-6190-final-team-project/channels/split_random/sample/validation/\n"
     ]
    }
   ],
   "source": [
    "s3train = 's3://{}/{}/{}/{}/train/'.format(bucket, prefix_1, prefix_split_type, prefix_dataset)\n",
    "s3validation = 's3://{}/{}/{}/{}/validation/'.format(bucket, prefix_1, prefix_split_type, prefix_dataset)\n",
    "\n",
    "print(\"The input data is pulled from the following S3 locations:\")\n",
    "print(\"Training:\\t{}\".format(s3train))\n",
    "print(\"Validation:\\t{}\".format(s3validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define the channels as inputs into the image classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sagemaker.session.s3_input(s3train, \n",
    "                                        distribution='FullyReplicated', \n",
    "                                        content_type='application/x-recordio', \n",
    "                                        s3_data_type='S3Prefix')\n",
    "\n",
    "validation_data = sagemaker.session.s3_input(s3validation, \n",
    "                                             distribution='FullyReplicated', \n",
    "                                             content_type='application/x-recordio', \n",
    "                                             s3_data_type='S3Prefix')\n",
    "\n",
    "data_channels = {'train': train_data, \n",
    "                 'validation': validation_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Instance Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This training session used the following instance: ml.p3.2xlarge\n"
     ]
    }
   ],
   "source": [
    "# Available Instances\n",
    "available_instances =['ml.p2.xlarge',              ### $1.26/hr\n",
    "                      'ml.p3.2xlarge'              ### 4.284 /hr\n",
    "                     ]\n",
    "\n",
    "# Initialize Instance\n",
    "train_instance_type = available_instances[1]\n",
    "\n",
    "# Print Check\n",
    "print(\"This training session used the following instance: {}\".format(train_instance_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize\n",
    "#### Parameters\n",
    "The following steps define the algoritm parameters and hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_drive_ic = sagemaker.estimator.Estimator(training_image,\n",
    "                                              role_arn, \n",
    "                                              train_instance_count=1, \n",
    "                                              train_instance_type=train_instance_type,\n",
    "                                              train_volume_size = 50,\n",
    "                                              train_max_run = 360000,\n",
    "                                              input_mode= 'File',\n",
    "                                              output_path=s3_output_location,\n",
    "                                              sagemaker_session=sess_sage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_drive_ic.set_hyperparameters(num_layers = 18,\n",
    "                                  use_pretrained_model = 1,\n",
    "                                  image_shape = \"3,210,280\", #RGB Pictures, 210 x 280\n",
    "                                  num_classes = 10,\n",
    "                                  mini_batch_size = 128,\n",
    "                                  epochs = 5,\n",
    "                                  learning_rate = 0.01,\n",
    "                                  num_training_samples = num_training_samples,\n",
    "                                  precision_dtype = 'float16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Model\n",
    "With the data inputs defined, parameters and hyperparameters initialized, we can run the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-23 19:19:45 Starting - Starting the training job...\n",
      "2020-04-23 19:19:46 Starting - Launching requested ML instances.........\n",
      "2020-04-23 19:21:22 Starting - Preparing the instances for training......\n",
      "2020-04-23 19:22:40 Downloading - Downloading input data\n",
      "2020-04-23 19:22:40 Training - Downloading the training image.....\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34m[04/23/2020 19:23:39 INFO 139816725485376] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/image_classification/default-input.json: {u'beta_1': 0.9, u'gamma': 0.9, u'beta_2': 0.999, u'optimizer': u'sgd', u'use_pretrained_model': 0, u'eps': 1e-08, u'epochs': 30, u'lr_scheduler_factor': 0.1, u'num_layers': 152, u'image_shape': u'3,224,224', u'precision_dtype': u'float32', u'mini_batch_size': 32, u'weight_decay': 0.0001, u'learning_rate': 0.1, u'momentum': 0}\u001b[0m\n",
      "\u001b[34m[04/23/2020 19:23:39 INFO 139816725485376] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {u'learning_rate': u'0.01', u'use_pretrained_model': u'1', u'epochs': u'2', u'num_training_samples': u'1567', u'num_layers': u'18', u'image_shape': u'3,210,280', u'mini_batch_size': u'128', u'precision_dtype': u'float16', u'num_classes': u'10'}\u001b[0m\n",
      "\u001b[34m[04/23/2020 19:23:39 INFO 139816725485376] Final configuration: {u'optimizer': u'sgd', u'learning_rate': u'0.01', u'epochs': u'2', u'lr_scheduler_factor': 0.1, u'num_layers': u'18', u'precision_dtype': u'float16', u'mini_batch_size': u'128', u'num_classes': u'10', u'beta_1': 0.9, u'beta_2': 0.999, u'use_pretrained_model': u'1', u'eps': 1e-08, u'weight_decay': 0.0001, u'momentum': 0, u'image_shape': u'3,210,280', u'gamma': 0.9, u'num_training_samples': u'1567'}\u001b[0m\n",
      "\u001b[34m[04/23/2020 19:23:39 INFO 139816725485376] Searching for .rec files in /opt/ml/input/data/train.\u001b[0m\n",
      "\u001b[34m[04/23/2020 19:23:39 INFO 139816725485376] Searching for .rec files in /opt/ml/input/data/validation.\u001b[0m\n",
      "\u001b[34m[04/23/2020 19:23:39 INFO 139816725485376] use_pretrained_model: 1\u001b[0m\n",
      "\u001b[34m[04/23/2020 19:23:39 INFO 139816725485376] multi_label: 0\u001b[0m\n",
      "\u001b[34m[04/23/2020 19:23:39 INFO 139816725485376] Using pretrained model for initializing weights and transfer learning.\u001b[0m\n",
      "\u001b[34m[04/23/2020 19:23:39 INFO 139816725485376] ---- Parameters ----\u001b[0m\n",
      "\u001b[34m[04/23/2020 19:23:39 INFO 139816725485376] num_layers: 18\u001b[0m\n",
      "\u001b[34m[04/23/2020 19:23:39 INFO 139816725485376] data type: <type 'numpy.float16'>\u001b[0m\n",
      "\u001b[34m[04/23/2020 19:23:39 INFO 139816725485376] epochs: 2\u001b[0m\n",
      "\u001b[34m[04/23/2020 19:23:39 INFO 139816725485376] optimizer: sgd\u001b[0m\n",
      "\u001b[34m[04/23/2020 19:23:39 INFO 139816725485376] momentum: 0.9\u001b[0m\n",
      "\u001b[34m[04/23/2020 19:23:39 INFO 139816725485376] weight_decay: 0.0001\u001b[0m\n",
      "\u001b[34m[04/23/2020 19:23:39 INFO 139816725485376] learning_rate: 0.01\u001b[0m\n",
      "\u001b[34m[04/23/2020 19:23:39 INFO 139816725485376] num_training_samples: 1567\u001b[0m\n",
      "\u001b[34m[04/23/2020 19:23:39 INFO 139816725485376] mini_batch_size: 128\u001b[0m\n",
      "\u001b[34m[04/23/2020 19:23:39 INFO 139816725485376] image_shape: 3,210,280\u001b[0m\n",
      "\u001b[34m[04/23/2020 19:23:39 INFO 139816725485376] num_classes: 10\u001b[0m\n",
      "\u001b[34m[04/23/2020 19:23:39 INFO 139816725485376] augmentation_type: None\u001b[0m\n",
      "\u001b[34m[04/23/2020 19:23:39 INFO 139816725485376] kv_store: device\u001b[0m\n",
      "\u001b[34m[04/23/2020 19:23:39 INFO 139816725485376] checkpoint_frequency not set, will store the best model\u001b[0m\n",
      "\u001b[34m[04/23/2020 19:23:39 INFO 139816725485376] --------------------\u001b[0m\n",
      "\u001b[34m[19:23:39] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_ecl_Cuda_10.1.x.2633.0/AL2012/generic-flavor/src/src/nnvm/legacy_json_util.cc:209: Loading symbol saved by previous version v0.8.0. Attempting to upgrade...\u001b[0m\n",
      "\u001b[34m[19:23:39] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_ecl_Cuda_10.1.x.2633.0/AL2012/generic-flavor/src/src/nnvm/legacy_json_util.cc:217: Symbol successfully upgraded!\u001b[0m\n",
      "\u001b[34m[04/23/2020 19:23:39 INFO 139816725485376] Setting number of threads: 7\u001b[0m\n",
      "\n",
      "2020-04-23 19:23:36 Training - Training image download completed. Training in progress.\u001b[34m[19:23:46] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_ecl_Cuda_10.1.x.2633.0/AL2012/generic-flavor/src/src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\u001b[0m\n",
      "\u001b[34m[04/23/2020 19:23:49 INFO 139816725485376] Epoch[0] Train-accuracy=0.376953\u001b[0m\n",
      "\u001b[34m[04/23/2020 19:23:49 INFO 139816725485376] Epoch[0] Time cost=2.812\u001b[0m\n",
      "\u001b[34m[04/23/2020 19:23:50 INFO 139816725485376] Epoch[0] Validation-accuracy=0.601562\u001b[0m\n",
      "\u001b[34m[04/23/2020 19:23:50 INFO 139816725485376] Storing the best model with validation accuracy: 0.601562\u001b[0m\n",
      "\u001b[34m[04/23/2020 19:23:50 INFO 139816725485376] Saved checkpoint to \"/opt/ml/model/image-classification-0001.params\"\u001b[0m\n",
      "\u001b[34m[04/23/2020 19:23:50 INFO 139816725485376] Saved checkpoint to \"/opt/ml/model/cpu/image-classification-0001.params\"\u001b[0m\n",
      "\u001b[34m[04/23/2020 19:23:51 INFO 139816725485376] Epoch[1] Train-accuracy=0.935547\u001b[0m\n",
      "\u001b[34m[04/23/2020 19:23:51 INFO 139816725485376] Epoch[1] Time cost=1.453\u001b[0m\n",
      "\u001b[34m[04/23/2020 19:23:52 INFO 139816725485376] Epoch[1] Validation-accuracy=0.914062\u001b[0m\n",
      "\u001b[34m[04/23/2020 19:23:52 INFO 139816725485376] Storing the best model with validation accuracy: 0.914062\u001b[0m\n",
      "\u001b[34m[04/23/2020 19:23:52 INFO 139816725485376] Saved checkpoint to \"/opt/ml/model/image-classification-0002.params\"\u001b[0m\n",
      "\u001b[34m[04/23/2020 19:23:52 INFO 139816725485376] Saved checkpoint to \"/opt/ml/model/cpu/image-classification-0002.params\"\u001b[0m\n",
      "\n",
      "2020-04-23 19:24:08 Uploading - Uploading generated training model\n",
      "2020-04-23 19:24:08 Completed - Training job completed\n",
      "Training seconds: 102\n",
      "Billable seconds: 102\n"
     ]
    }
   ],
   "source": [
    "dist_drive_ic.fit(inputs = data_channels, logs = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait\n",
    "We need to insert a waiting stage in the process flow to ensure the model training is complete before downstream processes start. This should happen automatically, but we will add this step for caution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Job Name:\timage-classification-2020-04-23-19-19-43-941\n",
      "Training Job Status:\tCompleted\n"
     ]
    }
   ],
   "source": [
    "# Initialize Watier\n",
    "waiter = sm_client.get_waiter('training_job_completed_or_stopped')\n",
    "\n",
    "# Extract Training Job Name\n",
    "training_job_name = dist_drive_ic._current_job_name\n",
    "\n",
    "# Define Waiter Parameters\n",
    "waiter_params = {\n",
    "    'TrainingJobName' : training_job_name,\n",
    "    'WaiterConfig'  : {\n",
    "        'Delay' : 123,\n",
    "        'MaxAttemps' : 123\n",
    "    }\n",
    "}\n",
    "\n",
    "# Execute Waiter\n",
    "waiter.wait(**waiter_params)\n",
    "\n",
    "# Verify Status\n",
    "response = sm_client.describe_training_job(\n",
    "    TrainingJobName = training_job_name\n",
    ")\n",
    "\n",
    "print(\"Training Job Name:\\t{}\".format(response['TrainingJobName']))\n",
    "print(\"Training Job Status:\\t{}\".format(response['TrainingJobStatus']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Job Name: image-classification-2020-04-23-19-19-43-941\n",
      "\n",
      "Training Job Information:\n",
      "\n",
      "Model S3 Location: s3://dsba-6190-final-team-project/output/image-classification-2020-04-23-19-19-43-941/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# Training Job\n",
    "training_job_name = dist_drive_ic._current_job_name\n",
    "print(\"Training Job Name: {}\".format(training_job_name))\n",
    "print()\n",
    "\n",
    "# Extract Training Job Information\n",
    "info = sm_client.describe_training_job(TrainingJobName=training_job_name)\n",
    "print(\"Training Job Information:\")\n",
    "#print(info)\n",
    "print()\n",
    "\n",
    "# Define S3 Location for Model Artifacts\n",
    "model_s3_loc = info['ModelArtifacts']['S3ModelArtifacts']\n",
    "print(\"Model S3 Location: {}\".format(model_s3_loc))\n",
    "\n",
    "# Define Primary Container\n",
    "primary_container = {\n",
    "    'Image': training_image,\n",
    "    'ModelDataUrl': model_s3_loc,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial creation of model\n",
      "\n",
      "Model Name: image-classification-drivers-model-2020-04-23-19-24-33\n",
      "Model ARN: arn:aws:sagemaker:us-east-1:726963482731:model/image-classification-drivers-model-2020-04-23-19-24-33\n"
     ]
    }
   ],
   "source": [
    "timestamp = t.strftime('-%Y-%m-%d-%H-%M-%S', t.gmtime())\n",
    "model_name = label + \"-model\" + timestamp\n",
    "\n",
    "try:\n",
    "    \n",
    "    create_model_response = sm_client.create_model(\n",
    "        ModelName = model_name,\n",
    "        ExecutionRoleArn = role_arn,\n",
    "        PrimaryContainer = primary_container)\n",
    "    print(\"Initial creation of model\")\n",
    "\n",
    "except: \n",
    "    print(\"Model already created.\")\n",
    "\n",
    "print()\n",
    "print(\"Model Name: {}\".format(model_name))\n",
    "print(\"Model ARN: {}\".format(create_model_response['ModelArn']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endpoint Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Configuration name:\timage-classification-drivers-epc-2020-04-23-19-24-34\n"
     ]
    }
   ],
   "source": [
    "timestamp = t.strftime('-%Y-%m-%d-%H-%M-%S', t.gmtime())\n",
    "endpoint_config_name = label + '-epc' + timestamp\n",
    "variant_name = \"AllTraffic\"\n",
    "print('Endpoint Configuration name:\\t{}'.format(endpoint_config_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Endpoint Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial creation of endpoint configuration.\n",
      "\n",
      "Endpoint configuration name:\timage-classification-drivers-epc-2020-04-23-19-24-34\n",
      "Endpoint configuration arn:\tarn:aws:sagemaker:us-east-1:726963482731:endpoint-config/image-classification-drivers-epc-2020-04-23-19-24-34\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    endpoint_config_response = sm_client.create_endpoint_config(\n",
    "        EndpointConfigName = endpoint_config_name,\n",
    "        ProductionVariants=[\n",
    "            {\n",
    "            'InstanceType':'ml.m4.xlarge',\n",
    "            'InitialInstanceCount':1,\n",
    "            'ModelName':model_name,\n",
    "            'VariantName': variant_name,\n",
    "            'InitialVariantWeight':1\n",
    "            }\n",
    "        ])\n",
    "    print(\"Initial creation of endpoint configuration.\")\n",
    "\n",
    "except:\n",
    "    print('Endpoint configuration already created')\n",
    "\n",
    "print()\n",
    "print('Endpoint configuration name:\\t{}'.format(endpoint_config_name))\n",
    "print('Endpoint configuration arn:\\t{}'.format(endpoint_config_response['EndpointConfigArn']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint name: image-classification-drivers-endpoint\n"
     ]
    }
   ],
   "source": [
    "endpoint_name = label + '-endpoint'\n",
    "print('Endpoint name: {}'.format(endpoint_name))\n",
    "\n",
    "endpoint_params = {\n",
    "    'EndpointName': endpoint_name,\n",
    "    'EndpointConfigName': endpoint_config_name,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create / Update Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When updating an endpoint, we cannot update if the endpoint configuration does not change. This should not be a problem when executed in the final proces flow, but for working on this process, we want to avoid this error. So, an **if** is added to the **try** portion of the code block to verify endpoint configuration changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint updated.\n",
      "\n",
      "EndpointArn:\tarn:aws:sagemaker:us-east-1:726963482731:endpoint/image-classification-drivers-endpoint\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    repsonse = sm_client.describe_endpoint(EndpointName = endpoint_name)\n",
    "    if response['EndpointConfigName'] == endpoint_config_name:\n",
    "        print('Unable to Update. No change to Endpoint Configuration.')\n",
    "    else:\n",
    "        endpoint_response = sm_client.update_endpoint(**endpoint_params)\n",
    "        print('Endpoint updated.')\n",
    "        print()\n",
    "except:\n",
    "    endpoint_response = sm_client.create_endpoint(**endpoint_params)\n",
    "    print(\"Initial creation of endpoint.\")\n",
    "    print()\n",
    "\n",
    "print('EndpointArn:\\t{}'.format(endpoint_response['EndpointArn']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait\n",
    "We need to insert a waiting stage in the process flow to ensure the endpoint is **InService** before we can apply the autoscaling policy. If this stage is not here, we may get an error when we try to apply the autoscaling policy to an endpoint that is still being constructed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Name:\t\timage-classification-drivers-endpoint\n",
      "Endpoint Status:\tInService\n"
     ]
    }
   ],
   "source": [
    "# Initialize Watier\n",
    "waiter = sm_client.get_waiter('endpoint_in_service')\n",
    "\n",
    "# Define Waiter Parameters\n",
    "waiter_params = {\n",
    "    'EndpointName' : endpoint_name,\n",
    "    'WaiterConfig'  : {\n",
    "        'Delay' : 123,\n",
    "        'MaxAttemps' : 123\n",
    "    }\n",
    "}\n",
    "\n",
    "# Execute Waiter\n",
    "waiter.wait(**waiter_params)\n",
    "\n",
    "# Verify Status\n",
    "response = sm_client.describe_endpoint(\n",
    "    EndpointName = endpoint_name\n",
    ")\n",
    "\n",
    "print('Endpoint Name:\\t\\t{}'.format(response['EndpointName']))\n",
    "print('Endpoint Status:\\t{}'.format(response['EndpointStatus']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_name_space = 'sagemaker'\n",
    "resource_id = posixpath.join(\"endpoint\", endpoint_name,\"variant\", variant_name)\n",
    "scalable_dimension = 'sagemaker:variant:DesiredInstanceCount'\n",
    "resource_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register Scalable Target - Sagemaker Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalable_target_params = {\n",
    "    'ServiceNamespace' : service_name_space,\n",
    "    'ResourceId' : resource_id,\n",
    "    'ScalableDimension' : scalable_dimension,\n",
    "    'MinCapacity' : 1,\n",
    "    'MaxCapacity' : 4,\n",
    "    'RoleARN' : role_arn_auto_sc\n",
    "}\n",
    "\n",
    "json_form = json.dumps(scalable_target_params, indent=3)\n",
    "print(json_form)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply To Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = scale_client.register_scalable_target(**scalable_target_params)\n",
    "pprint.pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put Scaling Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_policy_params = {\n",
    "    'PolicyName' : 'image-classification-driver-endpoint-scaling',\n",
    "    'ServiceNamespace' : service_name_space,\n",
    "    'ResourceId' : resource_id,\n",
    "    'ScalableDimension' : scalable_dimension,\n",
    "    'PolicyType' :  'TargetTrackingScaling',\n",
    "    'TargetTrackingScalingPolicyConfiguration' : {\n",
    "        'TargetValue' : 3e4,\n",
    "        'PredefinedMetricSpecification' : {\n",
    "            'PredefinedMetricType' : 'SageMakerVariantInvocationsPerInstance'\n",
    "        },\n",
    "        'ScaleInCooldown': 120,\n",
    "        'ScaleOutCooldown': 300\n",
    "    }\n",
    "}\n",
    "\n",
    "scale_policy_json_form = json.dumps(scaling_policy_params, indent=3)\n",
    "print(scale_policy_json_form)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply To Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = scale_client.put_scaling_policy(**scaling_policy_params)\n",
    "pprint.pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Scaling Policy Was Attached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalable_policy_search_params = {\n",
    "    'ServiceNamespace' : service_name_space,\n",
    "}\n",
    "\n",
    "response = scale_client.describe_scaling_policies(**scalable_policy_search_params)\n",
    "pprint.pprint(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
