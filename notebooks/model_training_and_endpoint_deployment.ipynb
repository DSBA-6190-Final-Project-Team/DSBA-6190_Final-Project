{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is based on the preprocessing already locally performed. Training and Validation sets of images and LST files have been developed and placed in the correct structure, on S3. \n",
    "\n",
    "At this point, we can now simply perform the multiclass image classification training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time as t\n",
    "import os\n",
    "import json\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish AWS Parameters\n",
    "This step establishes AWS parameters used through this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::726963482731:role/dsba_6190_team_project\n"
     ]
    }
   ],
   "source": [
    "role = 'arn:aws:iam::726963482731:role/dsba_6190_team_project'\n",
    "\n",
    "bucket = \"dsba-6190-final-team-project\"\n",
    "prefix_1 = \"channels\"\n",
    "prefix_file_type = \"rec\"\n",
    "\n",
    "sess_sage = sagemaker.Session()\n",
    "sm_client = boto3.client('sagemaker')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Sagemaker Model\n",
    "This step imports the latest version of the Amazon Sagemaker Image Classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "811284229777.dkr.ecr.us-east-1.amazonaws.com/image-classification:latest\n"
     ]
    }
   ],
   "source": [
    "training_image = get_image_uri(sess_sage.boto_region_name, 'image-classification', repo_version=\"latest\")\n",
    "print (training_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "Two different data sets have been uploaded to S3. One is the complete dataset. The other is a 10% sample of the dataset. The 10% sample is for troubleshooting training and deployment of the Sagemaker Image Classification algorithm.\n",
    "\n",
    "There are only two differences between training the model with the sample or complete dataset:\n",
    "\n",
    "* __Input Location__: We need to point the algorithm to different S3 locations. We will do this with the **prefix_dataset** variable, which will be defined at the beginning of each dataset's notebook section.\n",
    "* __Number of Training Samples__: The number of training samples will be different for the complete and the sample. Thes values are available in the Jupyter Notebook used to split the data and upload to S3.\n",
    "\n",
    "We will define the number of **training** samples for each dataset below. \n",
    "\n",
    "**Note**: *Currently this is a manual process. Future iterations of this process will automate this calculation.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_training_samples_complete = 15686\n",
    "num_training_samples_10 = 1567"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dataset\n",
    "This section defines the parameters of the dataset. By setting the split prefix and dataset prefix, it will direct the algorithm to the correct training and validation inputs. \n",
    "\n",
    "There are two varables which require definition:\n",
    "\n",
    "1. **Dataset**: The dataset is either the complete dataset, or it is the 10% sample dataset. The 10% sample was created for troubleshooting purposes. Final production will use the complete dataset.\n",
    "2. **Train/Validation Split Method**: Two different methods were developed to split the training data into a training and validation set. See the image processing notebook for more detail.\n",
    " * im2rec: This method was a random split, using the **im2rec.py** tool\n",
    " * split_drivers: This method divided the drivers into a training and validation set. Then, all the images associated with each driver are put into image training and validation sets. Using this method, all of the images associated with a driver are in either the training or validation set. No driver appears in both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are the inputs for the model:\n",
      "Split Method:\t\t\tsplit_random\n",
      "Dataset:\t\t\tsample\n",
      "# of Training Samples:\t\t1567\n"
     ]
    }
   ],
   "source": [
    "# Define Lists and Dictionary\n",
    "list_dataset = [\"complete\", \"sample\",]\n",
    "list_split_method = [\"split_random\", \"split_driver\"]\n",
    "\n",
    "training_sample_dict = {\n",
    "    \"sample-split_random\" : num_training_samples_10,\n",
    "    \"sample-split_driver\": num_training_samples_10, \n",
    "    \"complete-split_random\": num_training_samples_complete,\n",
    "    \"complete-split_driver\": num_training_samples_complete    \n",
    "}\n",
    "\n",
    "# Define Data Inputs\n",
    "prefix_dataset = list_dataset[1] #0 = complete / 1 = sample\n",
    "prefix_split_type = list_split_method[0]  #0 = split_random / 1 = split_drivers\n",
    "\n",
    "# Extract Number of Training Samples\n",
    "key_training_sample = prefix_dataset + \"-\" +prefix_split_type\n",
    "num_training_samples = training_sample_dict[key_training_sample]\n",
    "\n",
    "print(\"The following are the inputs for the model:\")\n",
    "print(\"Split Method:\\t\\t\\t{}\".format(prefix_split_type))\n",
    "print(\"Dataset:\\t\\t\\t{}\".format(prefix_dataset))\n",
    "print(\"# of Training Samples:\\t\\t{}\".format(num_training_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Output Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://dsba-6190-final-team-project/output\n"
     ]
    }
   ],
   "source": [
    "s3_output_location = 's3://{}/output'.format(bucket)\n",
    "print(s3_output_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Input Location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we establish the data input channels. As we are using RecordIO data format, only two channels are required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input data is pulled from the following S3 locations:\n",
      "Training:\ts3://dsba-6190-final-team-project/channels/split_random/sample/train/\n",
      "Validation:\ts3://dsba-6190-final-team-project/channels/split_random/sample/validation/\n"
     ]
    }
   ],
   "source": [
    "s3train = 's3://{}/{}/{}/{}/train/'.format(bucket, prefix_1, prefix_split_type, prefix_dataset)\n",
    "s3validation = 's3://{}/{}/{}/{}/validation/'.format(bucket, prefix_1, prefix_split_type, prefix_dataset)\n",
    "\n",
    "print(\"The input data is pulled from the following S3 locations:\")\n",
    "print(\"Training:\\t{}\".format(s3train))\n",
    "print(\"Validation:\\t{}\".format(s3validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define the channels as inputs into the image classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': <sagemaker.inputs.s3_input object at 0x7f74b406b208>, 'validation': <sagemaker.inputs.s3_input object at 0x7f74b406b128>}\n"
     ]
    }
   ],
   "source": [
    "train_data = sagemaker.session.s3_input(s3train, \n",
    "                                        distribution='FullyReplicated', \n",
    "                                        content_type='application/x-recordio', \n",
    "                                        s3_data_type='S3Prefix')\n",
    "\n",
    "validation_data = sagemaker.session.s3_input(s3validation, \n",
    "                                             distribution='FullyReplicated', \n",
    "                                             content_type='application/x-recordio', \n",
    "                                             s3_data_type='S3Prefix')\n",
    "\n",
    "data_channels = {'train': train_data, \n",
    "                 'validation': validation_data}\n",
    "\n",
    "print(data_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Instance Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This training session used the following instance: ml.p3.2xlarge\n"
     ]
    }
   ],
   "source": [
    "# Available Instances\n",
    "available_instances =['ml.p2.xlarge',              ### $1.26/hr\n",
    "                      'ml.p3.2xlarge'              ### 4.284 /hr\n",
    "                     ]\n",
    "\n",
    "# Initialize Instance\n",
    "train_instance_type = available_instances[1]\n",
    "\n",
    "# Print Check\n",
    "print(\"This training session used the following instance: {}\".format(train_instance_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize\n",
    "#### Parameters\n",
    "The following steps define the algoritm parameters and hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_drive_ic = sagemaker.estimator.Estimator(training_image,\n",
    "                                              role, \n",
    "                                              train_instance_count=1, \n",
    "                                              train_instance_type=train_instance_type,\n",
    "                                              train_volume_size = 50,\n",
    "                                              train_max_run = 360000,\n",
    "                                              input_mode= 'File',\n",
    "                                              output_path=s3_output_location,\n",
    "                                              sagemaker_session=sess_sage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_drive_ic.set_hyperparameters(num_layers = 18,\n",
    "                                  use_pretrained_model = 1,\n",
    "                                  image_shape = \"3,210,280\", #RGB Pictures, 210 x 280\n",
    "                                  num_classes = 10,\n",
    "                                  mini_batch_size = 128,\n",
    "                                  epochs = 2,\n",
    "                                  learning_rate = 0.01,\n",
    "                                  num_training_samples = num_training_samples,\n",
    "                                  precision_dtype = 'float16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Model\n",
    "With the data inputs defined, parameters and hyperparameters initialized, we can run the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-22 20:37:28 Starting - Starting the training job...\n",
      "2020-04-22 20:37:30 Starting - Launching requested ML instances......\n",
      "2020-04-22 20:38:36 Starting - Preparing the instances for training......\n",
      "2020-04-22 20:39:45 Downloading - Downloading input data...\n",
      "2020-04-22 20:40:01 Training - Downloading the training image.....\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34m[04/22/2020 20:41:05 INFO 140660904576832] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/image_classification/default-input.json: {u'beta_1': 0.9, u'gamma': 0.9, u'beta_2': 0.999, u'optimizer': u'sgd', u'use_pretrained_model': 0, u'eps': 1e-08, u'epochs': 30, u'lr_scheduler_factor': 0.1, u'num_layers': 152, u'image_shape': u'3,224,224', u'precision_dtype': u'float32', u'mini_batch_size': 32, u'weight_decay': 0.0001, u'learning_rate': 0.1, u'momentum': 0}\u001b[0m\n",
      "\u001b[34m[04/22/2020 20:41:05 INFO 140660904576832] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {u'learning_rate': u'0.01', u'use_pretrained_model': u'1', u'epochs': u'2', u'num_training_samples': u'1567', u'num_layers': u'18', u'image_shape': u'3,210,280', u'mini_batch_size': u'128', u'precision_dtype': u'float16', u'num_classes': u'10'}\u001b[0m\n",
      "\u001b[34m[04/22/2020 20:41:05 INFO 140660904576832] Final configuration: {u'optimizer': u'sgd', u'learning_rate': u'0.01', u'epochs': u'2', u'lr_scheduler_factor': 0.1, u'num_layers': u'18', u'precision_dtype': u'float16', u'mini_batch_size': u'128', u'num_classes': u'10', u'beta_1': 0.9, u'beta_2': 0.999, u'use_pretrained_model': u'1', u'eps': 1e-08, u'weight_decay': 0.0001, u'momentum': 0, u'image_shape': u'3,210,280', u'gamma': 0.9, u'num_training_samples': u'1567'}\u001b[0m\n",
      "\u001b[34m[04/22/2020 20:41:05 INFO 140660904576832] Searching for .rec files in /opt/ml/input/data/train.\u001b[0m\n",
      "\u001b[34m[04/22/2020 20:41:05 INFO 140660904576832] Searching for .rec files in /opt/ml/input/data/validation.\u001b[0m\n",
      "\u001b[34m[04/22/2020 20:41:05 INFO 140660904576832] use_pretrained_model: 1\u001b[0m\n",
      "\u001b[34m[04/22/2020 20:41:05 INFO 140660904576832] multi_label: 0\u001b[0m\n",
      "\u001b[34m[04/22/2020 20:41:05 INFO 140660904576832] Using pretrained model for initializing weights and transfer learning.\u001b[0m\n",
      "\u001b[34m[04/22/2020 20:41:05 INFO 140660904576832] ---- Parameters ----\u001b[0m\n",
      "\u001b[34m[04/22/2020 20:41:05 INFO 140660904576832] num_layers: 18\u001b[0m\n",
      "\u001b[34m[04/22/2020 20:41:05 INFO 140660904576832] data type: <type 'numpy.float16'>\u001b[0m\n",
      "\u001b[34m[04/22/2020 20:41:05 INFO 140660904576832] epochs: 2\u001b[0m\n",
      "\u001b[34m[04/22/2020 20:41:05 INFO 140660904576832] optimizer: sgd\u001b[0m\n",
      "\u001b[34m[04/22/2020 20:41:05 INFO 140660904576832] momentum: 0.9\u001b[0m\n",
      "\u001b[34m[04/22/2020 20:41:05 INFO 140660904576832] weight_decay: 0.0001\u001b[0m\n",
      "\u001b[34m[04/22/2020 20:41:05 INFO 140660904576832] learning_rate: 0.01\u001b[0m\n",
      "\u001b[34m[04/22/2020 20:41:05 INFO 140660904576832] num_training_samples: 1567\u001b[0m\n",
      "\u001b[34m[04/22/2020 20:41:05 INFO 140660904576832] mini_batch_size: 128\u001b[0m\n",
      "\u001b[34m[04/22/2020 20:41:05 INFO 140660904576832] image_shape: 3,210,280\u001b[0m\n",
      "\u001b[34m[04/22/2020 20:41:05 INFO 140660904576832] num_classes: 10\u001b[0m\n",
      "\u001b[34m[04/22/2020 20:41:05 INFO 140660904576832] augmentation_type: None\u001b[0m\n",
      "\u001b[34m[04/22/2020 20:41:05 INFO 140660904576832] kv_store: device\u001b[0m\n",
      "\u001b[34m[04/22/2020 20:41:05 INFO 140660904576832] checkpoint_frequency not set, will store the best model\u001b[0m\n",
      "\u001b[34m[04/22/2020 20:41:05 INFO 140660904576832] --------------------\u001b[0m\n",
      "\u001b[34m[20:41:05] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_ecl_Cuda_10.1.x.2633.0/AL2012/generic-flavor/src/src/nnvm/legacy_json_util.cc:209: Loading symbol saved by previous version v0.8.0. Attempting to upgrade...\u001b[0m\n",
      "\u001b[34m[20:41:05] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_ecl_Cuda_10.1.x.2633.0/AL2012/generic-flavor/src/src/nnvm/legacy_json_util.cc:217: Symbol successfully upgraded!\u001b[0m\n",
      "\u001b[34m[04/22/2020 20:41:05 INFO 140660904576832] Setting number of threads: 7\u001b[0m\n",
      "\u001b[34m[20:41:13] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_ecl_Cuda_10.1.x.2633.0/AL2012/generic-flavor/src/src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\u001b[0m\n",
      "\u001b[34m[04/22/2020 20:41:16 INFO 140660904576832] Epoch[0] Train-accuracy=0.375000\u001b[0m\n",
      "\u001b[34m[04/22/2020 20:41:16 INFO 140660904576832] Epoch[0] Time cost=2.870\u001b[0m\n",
      "\u001b[34m[04/22/2020 20:41:16 INFO 140660904576832] Epoch[0] Validation-accuracy=0.601562\u001b[0m\n",
      "\u001b[34m[04/22/2020 20:41:16 INFO 140660904576832] Storing the best model with validation accuracy: 0.601562\u001b[0m\n",
      "\u001b[34m[04/22/2020 20:41:16 INFO 140660904576832] Saved checkpoint to \"/opt/ml/model/image-classification-0001.params\"\u001b[0m\n",
      "\u001b[34m[04/22/2020 20:41:16 INFO 140660904576832] Saved checkpoint to \"/opt/ml/model/cpu/image-classification-0001.params\"\u001b[0m\n",
      "\n",
      "2020-04-22 20:41:22 Uploading - Uploading generated training model\u001b[34m[04/22/2020 20:41:18 INFO 140660904576832] Epoch[1] Train-accuracy=0.934896\u001b[0m\n",
      "\u001b[34m[04/22/2020 20:41:18 INFO 140660904576832] Epoch[1] Time cost=1.585\u001b[0m\n",
      "\u001b[34m[04/22/2020 20:41:18 INFO 140660904576832] Epoch[1] Validation-accuracy=0.908854\u001b[0m\n",
      "\u001b[34m[04/22/2020 20:41:18 INFO 140660904576832] Storing the best model with validation accuracy: 0.908854\u001b[0m\n",
      "\u001b[34m[04/22/2020 20:41:19 INFO 140660904576832] Saved checkpoint to \"/opt/ml/model/image-classification-0002.params\"\u001b[0m\n",
      "\u001b[34m[04/22/2020 20:41:19 INFO 140660904576832] Saved checkpoint to \"/opt/ml/model/cpu/image-classification-0002.params\"\u001b[0m\n",
      "\n",
      "2020-04-22 20:41:34 Completed - Training job completed\n",
      "Training seconds: 109\n",
      "Billable seconds: 109\n",
      "CPU times: user 529 ms, sys: 36 ms, total: 565 ms\n",
      "Wall time: 4min 42s\n"
     ]
    }
   ],
   "source": [
    "dist_drive_ic.fit(inputs = data_channels, logs = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Tag For Future Use\n",
    "aws_component_name = \"image-classification-drivers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Job Name: image-classification-2020-04-22-20-37-28-601\n",
      "\n",
      "Training Job Information:\n",
      "\n",
      "Model S3 Location: s3://dsba-6190-final-team-project/output/image-classification-2020-04-22-20-37-28-601/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# Training Job\n",
    "training_job_name = dist_drive_ic._current_job_name\n",
    "print(\"Training Job Name: {}\".format(training_job_name))\n",
    "print()\n",
    "\n",
    "# Extract Training Job Information\n",
    "info = sm_client.describe_training_job(TrainingJobName=training_job_name)\n",
    "print(\"Training Job Information:\")\n",
    "#print(info)\n",
    "print()\n",
    "\n",
    "# Define S3 Location for Model Artifacts\n",
    "model_s3_loc = info['ModelArtifacts']['S3ModelArtifacts']\n",
    "print(\"Model S3 Location: {}\".format(model_s3_loc))\n",
    "\n",
    "# Define Primary Container\n",
    "primary_container = {\n",
    "    'Image': training_image,\n",
    "    'ModelDataUrl': model_s3_loc,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial creation of model\n",
      "\n",
      "Model Name: image-classification-drivers-model-2020-04-22-17-33-10\n",
      "Model ARN: arn:aws:sagemaker:us-east-1:726963482731:model/image-classification-drivers-model-2020-04-22-17-33-10\n"
     ]
    }
   ],
   "source": [
    "timestamp = t.strftime('-%Y-%m-%d-%H-%M-%S', t.gmtime())\n",
    "model_name = aws_component_name + \"-model\" + timestamp\n",
    "\n",
    "try:\n",
    "    \n",
    "    create_model_response = sm_client.create_model(\n",
    "        ModelName = model_name,\n",
    "        ExecutionRoleArn = role,\n",
    "        PrimaryContainer = primary_container)\n",
    "    print(\"Initial creation of model\")\n",
    "\n",
    "except: \n",
    "    print(\"Model already created.\")\n",
    "\n",
    "print()\n",
    "print(\"Model Name: {}\".format(model_name))\n",
    "print(\"Model ARN: {}\".format(create_model_response['ModelArn']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endpoint Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Configuration name: image-classification-drivers-epc-2020-04-22-17-33-10\n"
     ]
    }
   ],
   "source": [
    "timestamp = t.strftime('-%Y-%m-%d-%H-%M-%S', t.gmtime())\n",
    "endpoint_config_name = aws_component_name + '-epc' + timestamp\n",
    "variant_name = \"AllTraffic\"\n",
    "print('Endpoint Configuration name: {}'.format(endpoint_config_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Endpoint Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial creation of endpoint configuration.\n",
      "\n",
      "Endpoint configuration name: image-classification-drivers-epc-2020-04-22-17-33-10\n",
      "Endpoint configuration arn:  arn:aws:sagemaker:us-east-1:726963482731:endpoint-config/image-classification-drivers-epc-2020-04-22-17-33-10\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "        'InstanceType':'ml.m4.xlarge',\n",
    "        'InitialInstanceCount':1,\n",
    "        'ModelName':model_name,\n",
    "        'VariantName': variant_name,\n",
    "        'InitialVariantWeight':1\n",
    "        }\n",
    "    ])\n",
    "    print(\"Initial creation of endpoint configuration.\")\n",
    "\n",
    "except:\n",
    "    print('Endpoint configuration already created')\n",
    "\n",
    "print()\n",
    "print('Endpoint configuration name: {}'.format(endpoint_config_name))\n",
    "print('Endpoint configuration arn:  {}'.format(endpoint_config_response['EndpointConfigArn']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint name: image-classification-drivers-endpoint\n"
     ]
    }
   ],
   "source": [
    "endpoint_name = aws_component_name + '-endpoint'\n",
    "print('Endpoint name: {}'.format(endpoint_name))\n",
    "\n",
    "endpoint_params = {\n",
    "    'EndpointName': endpoint_name,\n",
    "    'EndpointConfigName': endpoint_config_name,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create / Update Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the updating of and endpoint, we need to first verify the endpoint is in service. So we'll add a loop to verify that the endpoint is in service before we update it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial creation of endpoint.\n",
      "\n",
      "EndpointArn = arn:aws:sagemaker:us-east-1:726963482731:endpoint/image-classification-drivers-endpoint\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sm_client.describe_endpoint(EndpointName = endpoint_name)\n",
    "    status = \"\"\n",
    "    while True:\n",
    "        if status == \"InService\":\n",
    "            break\n",
    "        status = sm_client.describe_endpoint(EndpointName = endpoint_name)['EndpointStatus']\n",
    "        \n",
    "    endpoint_response = sm_client.update_endpoint(**endpoint_params)\n",
    "    print('Endpoint updated.')\n",
    "    print()\n",
    "except:\n",
    "    endpoint_response = sm_client.create_endpoint(**endpoint_params)\n",
    "    print(\"Initial creation of endpoint.\")\n",
    "    print()\n",
    "\n",
    "print('EndpointArn = {}'.format(endpoint_response['EndpointArn']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish Boto3 Client - Application Autoscaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_client = boto3.client(\"application-autoscaling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_name_space = 'sagemaker'\n",
    "resource_id = os.path.join(\"endpoint\", endpoint_name,\"variant\", variant_name)\n",
    "scalable_dimension = 'sagemaker:variant:DesiredInstanceCount'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register Scalable Target - Sagemaker Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"ServiceNamespace\": \"sagemaker\",\n",
      "   \"ResourceId\": \"endpoint/image-classification-drivers-endpoint/variant/AllTraffic\",\n",
      "   \"ScalableDimension\": \"sagemaker:variant:DesiredInstanceCount\",\n",
      "   \"MinCapacity\": 1,\n",
      "   \"MaxCapacity\": 4,\n",
      "   \"RoleARN\": \"arn:aws:iam::726963482731:role/aws-service-role/sagemaker.application-autoscaling.amazonaws.com/AWSServiceRoleForApplicationAutoScaling_SageMakerEndpoint\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "scalable_target_params = {\n",
    "    'ServiceNamespace' : service_name_space,\n",
    "    'ResourceId' : resource_id,\n",
    "    'ScalableDimension' : scalable_dimension,\n",
    "    'MinCapacity' : 1,\n",
    "    'MaxCapacity' : 4,\n",
    "    'RoleARN' : \"arn:aws:iam::726963482731:role/aws-service-role/sagemaker.application-autoscaling.amazonaws.com/AWSServiceRoleForApplicationAutoScaling_SageMakerEndpoint\"\n",
    "}\n",
    "\n",
    "json_form = json.dumps(scalable_target_params, indent=3)\n",
    "print(json_form)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply To Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = scale_client.register_scalable_target(**scalable_target_params)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put Scaling Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"PolicyName\": \"image-classification-driver-endpoint-scaling\",\n",
      "   \"ServiceNamespace\": \"sagemaker\",\n",
      "   \"ResourceId\": \"endpoint/image-classification-drivers-endpoint/variant/AllTraffic\",\n",
      "   \"ScalableDimension\": \"sagemaker:variant:DesiredInstanceCount\",\n",
      "   \"PolicyType\": \"TargetTrackingScaling\",\n",
      "   \"TargetTrackingScalingPolicyConfiguration\": {\n",
      "      \"TargetValue\": 30000.0,\n",
      "      \"PredefinedMetricSpecification\": {\n",
      "         \"PredefinedMetricType\": \"SageMakerVariantInvocationsPerInstance\"\n",
      "      },\n",
      "      \"ScaleInCooldown\": 600,\n",
      "      \"ScaleOutCooldown\": 300\n",
      "   }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "scaling_policy_params = {\n",
    "    'PolicyName' : 'image-classification-driver-endpoint-scaling',\n",
    "    'ServiceNamespace' : service_name_space,\n",
    "    'ResourceId' : resource_id,\n",
    "    'ScalableDimension' : scalable_dimension,\n",
    "    'PolicyType' :  'TargetTrackingScaling',\n",
    "    'TargetTrackingScalingPolicyConfiguration' : {\n",
    "        'TargetValue' : 3e4,\n",
    "        'PredefinedMetricSpecification' : {\n",
    "            'PredefinedMetricType' : 'SageMakerVariantInvocationsPerInstance'\n",
    "        },\n",
    "        'ScaleInCooldown': 600,\n",
    "        'ScaleOutCooldown': 300\n",
    "    }\n",
    "}\n",
    "\n",
    "scale_policy_json_form = json.dumps(scaling_policy_params, indent=3)\n",
    "print(scale_policy_json_form)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply To Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PolicyARN': 'arn:aws:autoscaling:us-east-1:726963482731:scalingPolicy:97e51a19-cf1d-4553-b11f-d49c6c6865ce:resource/sagemaker/endpoint/image-classification-drivers-endpoint/variant/AllTraffic:policyName/image-classification-driver-endpoint-scaling',\n",
       " 'Alarms': [{'AlarmName': 'TargetTracking-endpoint/image-classification-drivers-endpoint/variant/AllTraffic-AlarmHigh-2f450b5c-5931-4f78-8ee7-24f890fa7cf3',\n",
       "   'AlarmARN': 'arn:aws:cloudwatch:us-east-1:726963482731:alarm:TargetTracking-endpoint/image-classification-drivers-endpoint/variant/AllTraffic-AlarmHigh-2f450b5c-5931-4f78-8ee7-24f890fa7cf3'},\n",
       "  {'AlarmName': 'TargetTracking-endpoint/image-classification-drivers-endpoint/variant/AllTraffic-AlarmLow-43a33091-3707-4e8b-b751-9b30501fe607',\n",
       "   'AlarmARN': 'arn:aws:cloudwatch:us-east-1:726963482731:alarm:TargetTracking-endpoint/image-classification-drivers-endpoint/variant/AllTraffic-AlarmLow-43a33091-3707-4e8b-b751-9b30501fe607'}],\n",
       " 'ResponseMetadata': {'RequestId': '50efe947-82ab-43a6-bdaf-0151f4dce38f',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '50efe947-82ab-43a6-bdaf-0151f4dce38f',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '925',\n",
       "   'date': 'Wed, 22 Apr 2020 18:01:15 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = scale_client.put_scaling_policy(**scaling_policy_params)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Scaling Policy Was Attached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ScalingPolicies': [{'PolicyARN': 'arn:aws:autoscaling:us-east-1:726963482731:scalingPolicy:97e51a19-cf1d-4553-b11f-d49c6c6865ce:resource/sagemaker/endpoint/image-classification-drivers-endpoint/variant/AllTraffic:policyName/image-classification-driver-endpoint-scaling',\n",
       "   'PolicyName': 'image-classification-driver-endpoint-scaling',\n",
       "   'ServiceNamespace': 'sagemaker',\n",
       "   'ResourceId': 'endpoint/image-classification-drivers-endpoint/variant/AllTraffic',\n",
       "   'ScalableDimension': 'sagemaker:variant:DesiredInstanceCount',\n",
       "   'PolicyType': 'TargetTrackingScaling',\n",
       "   'TargetTrackingScalingPolicyConfiguration': {'TargetValue': 30000.0,\n",
       "    'PredefinedMetricSpecification': {'PredefinedMetricType': 'SageMakerVariantInvocationsPerInstance'},\n",
       "    'ScaleOutCooldown': 300,\n",
       "    'ScaleInCooldown': 600},\n",
       "   'Alarms': [{'AlarmName': 'TargetTracking-endpoint/image-classification-drivers-endpoint/variant/AllTraffic-AlarmHigh-2f450b5c-5931-4f78-8ee7-24f890fa7cf3',\n",
       "     'AlarmARN': 'arn:aws:cloudwatch:us-east-1:726963482731:alarm:TargetTracking-endpoint/image-classification-drivers-endpoint/variant/AllTraffic-AlarmHigh-2f450b5c-5931-4f78-8ee7-24f890fa7cf3'},\n",
       "    {'AlarmName': 'TargetTracking-endpoint/image-classification-drivers-endpoint/variant/AllTraffic-AlarmLow-43a33091-3707-4e8b-b751-9b30501fe607',\n",
       "     'AlarmARN': 'arn:aws:cloudwatch:us-east-1:726963482731:alarm:TargetTracking-endpoint/image-classification-drivers-endpoint/variant/AllTraffic-AlarmLow-43a33091-3707-4e8b-b751-9b30501fe607'}],\n",
       "   'CreationTime': datetime.datetime(2020, 4, 22, 18, 1, 14, 934000, tzinfo=tzlocal())}],\n",
       " 'ResponseMetadata': {'RequestId': '2f68a6d1-24bf-46df-9373-4f404ab9c4c4',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '2f68a6d1-24bf-46df-9373-4f404ab9c4c4',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '1459',\n",
       "   'date': 'Wed, 22 Apr 2020 18:01:21 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalable_policy_search_params = {\n",
    "    'ServiceNamespace' : service_name_space,\n",
    "}\n",
    "\n",
    "response = scale_client.describe_scaling_policies(**scalable_policy_search_params)\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
