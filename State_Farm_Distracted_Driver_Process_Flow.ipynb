{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "State Farm Distracted Driver Process Flow.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOmdM/bnlYP2JOUda8xK5hl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DSBA-6190-Final-Project-Team/DSBA-6190_Final-Project/blob/master/State_Farm_Distracted_Driver_Process_Flow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZ1CPjQE_iGK",
        "colab_type": "text"
      },
      "source": [
        "# Data\n",
        "The data set is the [State Farm Distracted Driver](https://www.kaggle.com/c/state-farm-distracted-driver-detection) dataset hosted on Kaggle.\n",
        "\n",
        "The Kaggle page provides three items: \n",
        "1. a list of training images, their subject (driver) id, and class id (CSV)\n",
        "2. a sample_submission.csv - a sample submission file in the correct format (CSV)\n",
        "3. zipped folder of all (train/test) images (ZIP)\n",
        "\n",
        "The data that the algorithm will train on is in the zipped folder. Within the folder are two sub-directories, train and test. The train directory contains the training set of the data, with each class of image within its own subfolder. The test directory contains only images, not seperated by class. It is to be used to score the final algorithm for Kaggle.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wOKYYpDCG7z",
        "colab_type": "text"
      },
      "source": [
        "# Environment\n",
        "The current plan is to generate a model in Amazon Sagemaker. A Amazon Sagemaker Notebook, using the Sagemaker Image Classification algorithm, will be used to generate a model. The Notebook will also deplot the model, once trained."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cCmuakiEK-e",
        "colab_type": "text"
      },
      "source": [
        "# Algorithm\n",
        "The Amazon Sagemaker Image Classification Algorithm has four main inputs:\n",
        "1. training set of images\n",
        "2. test set of images\n",
        "3. lst/rec file for trianing set\n",
        "4. lst/rec file for test set\n",
        "\n",
        "The lst or rec file (either acceptable) functions as a mapping resource, connecting each image to the image location and image class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sp840mVBIPA2",
        "colab_type": "text"
      },
      "source": [
        "# Data Preparation\n",
        "The provided test set will not be useful as a test set for the algorithm. The Sagemaker Image Classification Algorithm requires a labeled test set. Therefore, we will need to derive our own test set from the provided training set.\n",
        "\n",
        "Based on the [Towards Data blog post](https://towardsdatascience.com/how-i-tackled-my-first-kaggle-challenge-using-deep-learning-part-1-b0da29e1351b) walking through the same data, we are not going to split the training/test data strictly randomly. Instead, we will split the drivers randomly, so that a unique driver only exists in either the training or the test set.\n",
        "\n",
        "## Training / Test Set\n",
        "I propose as 80/20 split. \n",
        "\n",
        "The first step will be developing a list of unique drivers. We should also check the amount of pictures per driver to get an idea of how even the split of pictures per driver is. \n",
        "\n",
        "Then, we will generate a list of training and test drivers by randomly selecting from the unique list of drivers, using a 80/20 split.\n",
        "\n",
        "## LST/REC File Development\n",
        "The Image Classification Algorithm requires a file which maps the  images to the associated classes, for the training and testing sets. This can be in the form of a lst or rec file. \n",
        "\n",
        "There is python script available [here](https://mxnet.apache.org/api/faq/recordio) which will create these files. But these files must on your machine locally. I have already exported the files to S3. Therefore, I will need to redownload the files to a local machine and run this script. \n",
        "\n",
        "### Training / Test in the Mapping File\n",
        "Ideally, the training and test files would be physically seperated into two seperate folders. I would prefer not to do that, as the image folders have already been uploaded to S3. \n",
        "\n",
        "Therefore, I am going to try to keep the training and tes images in the same folder, but develop two mapping documents (as is required). That way, the mapping documents will scan the same image folder, but identify only the images on the training or testing mapping document.\n",
        "\n",
        "If this doesn't work I will revert to physiclaly seperating the training and test images.\n",
        "\n"
      ]
    }
  ]
}